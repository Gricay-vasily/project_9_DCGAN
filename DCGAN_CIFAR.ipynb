{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6535,"status":"ok","timestamp":1721539169780,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"pycU6aULtleW"},"outputs":[],"source":["# CIFAR10 DCGAN Example\n","# based on https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/\n","\n","from numpy import zeros\n","from numpy import ones\n","from numpy.random import randn\n","from numpy.random import randint\n","from tensorflow.keras.datasets.cifar10 import load_data\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Reshape\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Conv2DTranspose\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import Dropout\n","from matplotlib import pyplot\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1721539169781,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"QOPm5MIJuIve"},"outputs":[],"source":["# define the standalone discriminator model\n","def define_discriminator(in_shape=(32, 32, 3)):\n","    model = Sequential()\n","    # normal\n","    model.add(Conv2D(64, (3, 3), padding='same', input_shape=in_shape))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # downsample\n","    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # classifier\n","    model.add(Flatten())\n","    model.add(Dropout(0.4))\n","    model.add(Dense(1, activation='sigmoid'))\n","    # compile model\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1721539169782,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"prn2H2y5uLBy"},"outputs":[],"source":["# define the standalone generator model\n","def define_generator(latent_dim):\n","    model = Sequential()\n","    # foundation for 4x4 image\n","    n_nodes = 256 * 4 * 4\n","    model.add(Dense(n_nodes, input_dim=latent_dim))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Reshape((4, 4, 256)))\n","    # upsample to 8x8\n","    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 16x16\n","    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # upsample to 32x32\n","    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    # output layer\n","    model.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1721539169782,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"Vpl_Uo-xuMyR"},"outputs":[],"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","    # make weights in the discriminator not trainable\n","    d_model.trainable = False\n","    # connect them\n","    model = Sequential()\n","    # add generator\n","    model.add(g_model)\n","    # add the discriminator\n","    model.add(d_model)\n","    # compile model\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1721539169783,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"MuJ-BOFsuPhM"},"outputs":[],"source":["# load and prepare cifar10 training images\n","def load_real_samples():\n","    # load cifar10 dataset\n","    (trainX, _), (_, _) = load_data()\n","    # convert from unsigned ints to floats\n","    X = trainX.astype('float32')\n","    # scale from [0,255] to [-1,1]\n","    X = (X - 127.5) / 127.5\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":514,"status":"ok","timestamp":1721539173175,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"iGCN8jJRuQzk"},"outputs":[],"source":["# select real samples\n","def generate_real_samples(dataset, n_samples):\n","    # choose random instances\n","    ix = randint(0, dataset.shape[0], n_samples)\n","    # retrieve selected images\n","    X = dataset[ix]\n","    # generate 'real' class labels (1)\n","    y = ones((n_samples, 1))\n","    return X, y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1721539175125,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"Q_ZKEVZauSFI"},"outputs":[],"source":["# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","    # generate points in the latent space\n","    x_input = randn(latent_dim * n_samples)\n","    # reshape into a batch of inputs for the network\n","    x_input = x_input.reshape(n_samples, latent_dim)\n","    return x_input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1721539176417,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"UkWGhUaluTQf"},"outputs":[],"source":["# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","    # generate points in latent space\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    # predict outputs\n","    X = g_model.predict(x_input, verbose=0)\n","    # create 'fake' class labels (0)\n","    y = zeros((n_samples, 1))\n","    return X, y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":822,"status":"ok","timestamp":1721539177785,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"qD4zBrxTuUwx"},"outputs":[],"source":["# create and save a plot of generated images\n","def save_plot(examples, epoch, n=7):\n","    # scale from [-1,1] to [0,1]\n","    examples = (examples + 1) / 2.0\n","    # plot images\n","    for i in range(n * n):\n","        # define subplot\n","        pyplot.subplot(n, n, 1 + i)\n","        # turn off axis\n","        pyplot.axis('off')\n","        # plot raw pixel data\n","        pyplot.imshow(examples[i])\n","    # save plot to file\n","    # filename = 'generated_plot_e%03d.png' % (epoch+1)\n","    # pyplot.savefig(filename)\n","    pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":698,"status":"ok","timestamp":1721539179000,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"sMOV4g0duWno"},"outputs":[],"source":["# evaluate the discriminator, plot generated images, save generator model\n","def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n","    # prepare real samples\n","    X_real, y_real = generate_real_samples(dataset, n_samples)\n","    # evaluate discriminator on real examples\n","    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","    # prepare fake examples\n","    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","    # evaluate discriminator on fake examples\n","    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","    # summarize discriminator performance\n","    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real * 100, acc_fake * 100))\n","    # save plot\n","    save_plot(x_fake, epoch)\n","    # save the generator model tile file\n","    filename = 'generator_model.h5'\n","    g_model.save(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":751,"status":"ok","timestamp":1721539180272,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"fV79GbUquYX6"},"outputs":[],"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # manually enumerate epochs\n","    for i in range(n_epochs):\n","        # enumerate batches over the training set\n","        for j in range(bat_per_epo):\n","            # get randomly selected 'real' samples\n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            # update discriminator model weights\n","            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","            # generate 'fake' examples\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            # update discriminator model weights\n","            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","            # prepare points in latent space as input for the generator\n","            X_gan = generate_latent_points(latent_dim, n_batch)\n","            # create inverted labels for the fake samples\n","            y_gan = ones((n_batch, 1))\n","            # update the generator via the discriminator's error\n","            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n","            # summarize loss on this batch\n","            if j % 100 == 0:\n","                print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i + 1, j + 1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","        # evaluate the model performance, sometimes\n","        # if (i+1) % 10 == 0:\n","        summarize_performance(i, g_model, d_model, dataset, latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1721539182559,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"XmkHsG-MuaSo","outputId":"d3d7a0b9-da21-4ab7-8204-53c95b29c876"},"outputs":[],"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["d_model.metrics_names"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2010,"status":"ok","timestamp":1721539211268,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"KLMLlGJKucd2"},"outputs":[],"source":["# load image data\n","dataset = load_real_samples()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1721539264520,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"RczD0RFoufua","outputId":"dd729677-a887-4511-f9aa-61f240aa03c8"},"outputs":[],"source":["np.info(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["type(dataset)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":108471,"status":"error","timestamp":1721539379856,"user":{"displayName":"Vasily Gritsay","userId":"11000621382566770926"},"user_tz":-180},"id":"UbvBHUf9ufRi","outputId":"4f9593b8-ca17-49fb-e848-28fb137ccc85"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[11], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m y_gan \u001b[38;5;241m=\u001b[39m ones((n_batch, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# update the generator via the discriminator's error\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_gan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# summarize loss on this batch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2682\u001b[0m     )\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2684\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2686\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim, 20, 1000)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOXyWns07wPun+wYaAZa5xN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
