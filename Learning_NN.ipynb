{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gricay-vasily/project_9_DCGAN/blob/main/Learning_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HAnq6_2XEgT"
      },
      "source": [
        "# Навчання Deep Convolutional Generative Adversarial Network (DCGAN) на завантажених даних Cifar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Q-aFyxljOAVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRJnfY5sXEgT"
      },
      "source": [
        "## Завантаження і підготовка Дата-сетів"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8u2Eh9BXEgW"
      },
      "source": [
        "### Зчитування мета-даних"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvSte4oDY5F7"
      },
      "source": [
        "Посилання на дані"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc2nNalgYnNj"
      },
      "outputs": [],
      "source": [
        "URL_DIR = \"https://www.cs.toronto.edu/~kriz/\"\n",
        "cifar=10\n",
        "\n",
        "if cifar == 10:\n",
        "    FILE_NAME_CIFAR = \"cifar-10-python.tar.gz\"\n",
        "if cifar ==100:\n",
        "    FILE_NAME_CIFAR = \"cifar-100-python.tar.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83rOcvyHZkSt"
      },
      "source": [
        "Завантажимо дані"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYsnkkzoZj5x"
      },
      "outputs": [],
      "source": [
        "def load_and_unzip_cifar(url:str, file_name:str):\n",
        "  '''Завантаження і розпакування файлу-архіву, якщо ще цього не зроблено'''\n",
        "  from pathlib import Path\n",
        "  # Завантаження даних\n",
        "  full_url_to_load = url + file_name\n",
        "  print(full_url_to_load)\n",
        "  if Path(file_name).exists() and Path(file_name).is_file():\n",
        "    print(f\"Файл {file_name} вже є. Немає потреби його завантажувати!\")\n",
        "  else:\n",
        "    print(f\"Заватажуємо файл {file_name} \")\n",
        "    !wget $full_url_to_load\n",
        "  # Розпакування даних\n",
        "  # Створення робочої папки через stem i split - відсікання суфіксів\n",
        "  work_dir = Path(str((Path() / Path(file_name).stem)).split(\".\")[0])\n",
        "  # print(work_dir)\n",
        "  if work_dir.exists() and work_dir.is_dir():\n",
        "    print(f\"Директорія {work_dir} вже існує, перезаписуємо файли\")\n",
        "    # Перезаписуємо, бо є файли, які не дають видалити папку\n",
        "    !tar -xzvf $file_name\n",
        "  else:\n",
        "    print(f\"Розпакуємо файл {file_name}\")\n",
        "    !tar -xzvf $file_name\n",
        "\n",
        "load_and_unzip_cifar(URL_DIR, FILE_NAME_CIFAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfYbv3eOcfbZ"
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n",
        "  '''Десеріалізація даних з pickle-файлу'''\n",
        "  import pickle\n",
        "  with open(file, 'rb') as fo:\n",
        "      dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cifar == 10:\n",
        "  metadata_path = './cifar-10-batches-py/batches.meta' # шлях до даних\"\n",
        "  metadata = unpickle(metadata_path)\n",
        "  superclass_dict = dict(list(enumerate(metadata[b'label_names'])))\n",
        "if cifar ==100:\n",
        "  metadata_path = './cifar-100-python/meta' # шлях до даних\n",
        "  metadata = unpickle(metadata_path)\n",
        "  superclass_dict = dict(list(enumerate(metadata[b'coarse_label_names'])))"
      ],
      "metadata": {
        "id": "so6i2rKUEAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-dvkj6DXEgW"
      },
      "source": [
        "### Завантаження тренувальної та тестувальної вибірок (використовуючи суперкласи):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZzoTjKmXEgX"
      },
      "outputs": [],
      "source": [
        "if cifar == 100:\n",
        "  data_pre_path = './cifar-100-python/' # шлях до даних\n",
        "  # шляхи до файлів\n",
        "  data_train_path = data_pre_path + 'train'\n",
        "  data_test_path = data_pre_path + 'test'\n",
        "  # Зчитуємо словники\n",
        "  data_train_dict = unpickle(data_train_path)\n",
        "  data_test_dict = unpickle(data_test_path)\n",
        "  # Отримуємо дані (вибираємо coarse_labels щоб отримати всі 100 класів)\n",
        "  data_train = data_train_dict[b'data']\n",
        "  label_train = np.array(data_train_dict[b'coarse_labels'])\n",
        "  data_test = data_test_dict[b'data']\n",
        "  label_test = np.array(data_test_dict[b'coarse_labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завантаження тренувальної та тестувальної вибірок для Cifar-10:"
      ],
      "metadata": {
        "id": "hhZmR_u9GXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cifar == 10:\n",
        "  data_pre_path = './cifar-10-batches-py/' # шлях до даних\n",
        "  data_train = None\n",
        "  label_train = []\n",
        "  data_test = None\n",
        "  label_test = []\n",
        "  # Тренувальні вибірки\n",
        "  for _ in range(1,6):\n",
        "    data_train_dict = unpickle(data_pre_path + f\"data_batch_{_}\")\n",
        "    if _ == 1:\n",
        "      data_train = data_train_dict[b'data']\n",
        "    else:\n",
        "      data_train = np.vstack((data_train, data_train_dict[b'data']))\n",
        "    label_train += data_train_dict[b'labels']\n",
        "  #  Тестувальні вибірки\n",
        "  data_test_dict = unpickle(data_pre_path + \"test_batch\")\n",
        "  data_test = data_test_dict[b'data']\n",
        "  label_test = data_test_dict[b'labels']"
      ],
      "metadata": {
        "id": "xlW_kO6P6DOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEejGejaXEgX"
      },
      "source": [
        "Поверхнево дослідимо дані"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM-kjaIEXEgY"
      },
      "outputs": [],
      "source": [
        "type(data_train.shape), type(data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cZoWLveXEgZ"
      },
      "outputs": [],
      "source": [
        "data_train.shape, data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q4hdxPtXEgZ"
      },
      "outputs": [],
      "source": [
        "np.info(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfZN0XlfXEga"
      },
      "outputs": [],
      "source": [
        "data_train.reshape(len(data_train), 3, 32, 32).shape, data_test.reshape(len(data_test), 3, 32, 32).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FyEnk0rXEga"
      },
      "source": [
        "### Зміна розмірності зображень - виконувати лише раз у колабі!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V5Pd00UXEgb"
      },
      "outputs": [],
      "source": [
        "# Транспонується саме (0,2,3,1) - щоб отримати:\n",
        "# 0 - Позицію картинки\n",
        "# 2 - Значення висоти в пікселях\n",
        "# 3 - Значення ширини в пікселях\n",
        "# 1 - значення кольорів у RGB\n",
        "# Якщо набрати (0,3,2,1) - картинка перевертається на 90град - висота і ширина міняються місцями\n",
        "\n",
        "data_train = data_train.reshape(len(data_train), 3, 32, 32).transpose(0,2,3,1)\n",
        "data_test = data_test.reshape(len(data_test), 3, 32, 32).transpose(0,2,3,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d883O9sXEgb"
      },
      "outputs": [],
      "source": [
        "np.info(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_UW15r2XEgc"
      },
      "outputs": [],
      "source": [
        "_ = random.randint(0,len(data_train))\n",
        "print(f\"For picture #{_} - {label_train[_]} ({superclass_dict[label_train[_]]}):\")\n",
        "fig = plt.figure(figsize=(1,1))\n",
        "fig.add_subplot(1,1,1)\n",
        "plt.imshow(data_train[_])\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYDz98DSXEgc"
      },
      "source": [
        "Трохи більше картинок з тренувальної та тестувальної вибірок..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "391BTDRWXEgd"
      },
      "outputs": [],
      "source": [
        "def show_pictures_n_m(data,n,m:int):\n",
        "    fig = plt.figure(figsize=(max(n,m),max(n,m)))\n",
        "    for _ in range (n*m):\n",
        "        fig.add_subplot(n,m,_+1)\n",
        "        plt.imshow(data[_])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_pictures_n_m(data_train,5,5)\n",
        "show_pictures_n_m(data_test,3,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymUlMd5jXEgd"
      },
      "source": [
        "### Подальша підготовка даних для тренувань мережі"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbcxHO_Z3N7S"
      },
      "source": [
        "Перемішаємо тренувальні дані, використовуючи tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcC7aoOL9AST"
      },
      "outputs": [],
      "source": [
        "data_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = data_train.shape[0]\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "KnGhJbumICh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_images(data_set, buffer_size, batch_size):\n",
        "  prepared_images = data_set.astype(\"float32\")\n",
        "  prepared_images = (prepared_images - 255) / 255\n",
        "  prepared_images = tf.data.Dataset.from_tensor_slices(prepared_images)\n",
        "  #Перемішаємо дані випадковим чином\n",
        "  prepared_images = prepared_images.shuffle(buffer_size=buffer_size).batch(batch_size=batch_size)\n",
        "  return prepared_images"
      ],
      "metadata": {
        "id": "RKoJ_NlOMTTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvqHdZkKF4tJ"
      },
      "outputs": [],
      "source": [
        "train_images = prepare_images(data_train, BUFFER_SIZE, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images"
      ],
      "metadata": {
        "id": "AK345-ImHs2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Iw9_YDFeNW"
      },
      "outputs": [],
      "source": [
        "len(train_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Створення та тренування генератора і дискримінатора"
      ],
      "metadata": {
        "id": "1Fvt4flRJIJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Генератор - використовує шари `tf.keras.layers.Conv2DTranspose` (для підвищення дискретності),щоб створювати зображення з вихідного випадкового шуму (random noise). Починається шаром `Dense`, який приймає це початкове значення, а потім кілька разів підвищує дискретизацію, поки не досягне бажаного розміру зображення."
      ],
      "metadata": {
        "id": "QwRuLt3jURls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дискримінатор - Це класифікатор зображень на основі CNN.\n",
        "\n",
        "Він класифікує (визначає) якою є згенерована картинка - справжньою чи фейковою. Модель тренується показувати позитивне значення для справжньої картинки і негативне для фейкової."
      ],
      "metadata": {
        "id": "FwcfTZVuVNsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def real_or_fake(decision):\n",
        "  if decision>=0:\n",
        "    return \"Real\"\n",
        "  else:\n",
        "    return \"Fake\""
      ],
      "metadata": {
        "id": "kryrUjTcWQM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Змінні"
      ],
      "metadata": {
        "id": "JeEGokG1RpFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Рівень шуму\n",
        "NOISE_DIM = 100\n",
        "# Кількість генерованих зображень\n",
        "NUM_EXAMPLES_TO_GENERATE = 16"
      ],
      "metadata": {
        "id": "G5S91_euRibv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функції створення генератора та дискримінатора"
      ],
      "metadata": {
        "id": "J9k7fn7CIURo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  \"\"\"Створення генератора\"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8, 8, 256)))\n",
        "  assert model.output_shape == (None, 8, 8, 256)\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 32, 32, 3)\n",
        "\n",
        "  return model\n",
        "\n",
        "def build_discriminator():\n",
        "  \"\"\"Створення дискримінатора\"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n",
        "  model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "MXFkDrjuJePj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функції втрат для генератора і дискримінатора"
      ],
      "metadata": {
        "id": "CPWl09eLJ9YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  \"\"\"Ф-я втрат генератора - через бінарну кросс-ентропію\"\"\"\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  \"\"\"Ф-я втрат дискримінатора - через бінарну кросс-ентропію\"\"\"\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss"
      ],
      "metadata": {
        "id": "MXOz5oQtJ8Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Створення і налаштування генератора"
      ],
      "metadata": {
        "id": "1gXtRH3-Nj0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "generator.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "I5d5_2SfNjbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Створення і налаштування дискримінатора"
      ],
      "metadata": {
        "id": "ZCgnvVXdPlnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "discriminator.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "D4ZWT0hEPs4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерування зображення та його класифікація дискримінатором без навчання\n",
        "noise = tf.random.normal([1, NOISE_DIM])\n",
        "generated_image = generator(noise, training = False)\n",
        "decision = discriminator(generated_image).numpy()[0][0]\n",
        "print(f\"generated_image.shape = {generated_image.shape}\") #TensorShape([1, 32, 32, 3])\n",
        "print(f\"Точність decision = {decision}\")\n",
        "verdict = real_or_fake(decision)\n",
        "print(f\"Зображення - {verdict}\")\n",
        "plt.imshow(generated_image[generated_image.shape[0]-1, :,: ,0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MTJlAVSSTVEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тренування моделей"
      ],
      "metadata": {
        "id": "1E5SP3D6Oelj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def gen_train_step(images, batch_size):\n",
        "    noise = tf.random.normal([batch_size, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "KmV3S2MdOhrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X__3flDjwV9M"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "    image = tf.image.resize(image, [32, 32])\n",
        "    image = (image - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "    return image\n",
        "\n",
        "def load_dataset(data_path):\n",
        "    data = tf.keras.utils.get_file(data_path, origin=data_path)\n",
        "    images = []  # List to store processed images\n",
        "    for file in data:\n",
        "        image = preprocess_image(tf.io.read_file(file))\n",
        "        images.append(image)\n",
        "    return tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "        print(f'Epoch {epoch+1} completed')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}