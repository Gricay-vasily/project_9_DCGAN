{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDg7UcPYrMReCNFrSQd1al",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gricay-vasily/project_9_DCGAN/blob/main/generator_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViM9AsGpZH8t",
        "outputId": "0a07a5dc-35a6-4933-c857-fd537082f9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "2/2 [==============================] - 1s 203ms/step\n",
            "0 [D loss: 0.7017967104911804, acc.: 15.625%] [G loss: 0.6034762859344482]\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 0s 216ms/step\n",
            "2/2 [==============================] - 0s 209ms/step\n",
            "2/2 [==============================] - 1s 329ms/step\n",
            "2/2 [==============================] - 0s 203ms/step\n",
            "2/2 [==============================] - 0s 216ms/step\n",
            "2/2 [==============================] - 0s 197ms/step\n",
            "2/2 [==============================] - 0s 197ms/step\n",
            "2/2 [==============================] - 1s 310ms/step\n",
            "2/2 [==============================] - 0s 198ms/step\n",
            "2/2 [==============================] - 0s 210ms/step\n",
            "2/2 [==============================] - 0s 204ms/step\n",
            "2/2 [==============================] - 0s 205ms/step\n",
            "2/2 [==============================] - 1s 328ms/step\n",
            "2/2 [==============================] - 0s 222ms/step\n",
            "2/2 [==============================] - 0s 215ms/step\n",
            "2/2 [==============================] - 0s 199ms/step\n",
            "2/2 [==============================] - 0s 207ms/step\n",
            "2/2 [==============================] - 0s 200ms/step\n",
            "2/2 [==============================] - 1s 347ms/step\n",
            "2/2 [==============================] - 0s 200ms/step\n",
            "2/2 [==============================] - 0s 218ms/step\n",
            "2/2 [==============================] - 0s 215ms/step\n",
            "2/2 [==============================] - 0s 207ms/step\n",
            "2/2 [==============================] - 1s 316ms/step\n",
            "2/2 [==============================] - 0s 200ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 0s 206ms/step\n",
            "2/2 [==============================] - 0s 202ms/step\n",
            "2/2 [==============================] - 1s 326ms/step\n",
            "2/2 [==============================] - 0s 213ms/step\n",
            "2/2 [==============================] - 0s 214ms/step\n",
            "2/2 [==============================] - 0s 215ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 1s 338ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 0s 204ms/step\n",
            "2/2 [==============================] - 0s 199ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 1s 349ms/step\n",
            "2/2 [==============================] - 0s 202ms/step\n",
            "2/2 [==============================] - 0s 224ms/step\n",
            "2/2 [==============================] - 0s 213ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n",
            "2/2 [==============================] - 1s 324ms/step\n",
            "2/2 [==============================] - 0s 206ms/step\n",
            "2/2 [==============================] - 0s 194ms/step\n",
            "2/2 [==============================] - 0s 205ms/step\n",
            "2/2 [==============================] - 0s 197ms/step\n",
            "2/2 [==============================] - 1s 335ms/step\n",
            "2/2 [==============================] - 0s 205ms/step\n",
            "2/2 [==============================] - 0s 200ms/step\n",
            "2/2 [==============================] - 0s 213ms/step\n",
            "2/2 [==============================] - 0s 204ms/step\n",
            "2/2 [==============================] - 1s 355ms/step\n",
            "2/2 [==============================] - 0s 211ms/step\n",
            "2/2 [==============================] - 0s 213ms/step\n",
            "2/2 [==============================] - 0s 212ms/step\n",
            "2/2 [==============================] - 0s 197ms/step\n",
            "2/2 [==============================] - 0s 204ms/step\n",
            "2/2 [==============================] - 1s 321ms/step\n",
            "2/2 [==============================] - 0s 206ms/step\n",
            "2/2 [==============================] - 0s 204ms/step\n",
            "2/2 [==============================] - 0s 201ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from PIL import Image\n",
        "\n",
        "# Завантаження та підготовка датасету CIFAR-10\n",
        "def load_cifar10():\n",
        "    (x_train, y_train), (_, _) = cifar10.load_data()\n",
        "    x_train = (x_train.astype('float32') - 127.5) / 127.5  # нормалізація до [-1, 1]\n",
        "    return x_train\n",
        "\n",
        "# Створення генератора\n",
        "def build_generator(nodes=4, input_dim=100, alpha=0.2):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    n_f_nodes = 256 * nodes * nodes\n",
        "    model.add(layers.Dense(n_f_nodes, input_dim=input_dim))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Reshape((nodes, nodes, 256)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (nodes, nodes), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (nodes, nodes), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (nodes, nodes), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha))\n",
        "\n",
        "    model.add(layers.Conv2D(3, (3, 3), activation='tanh', padding='same'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Створення дискримінатора\n",
        "def build_discriminator(input_shape=(32, 32, 3), alpha=0.2):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(layers.LeakyReLU(alpha))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Побудова та компіляція GAN\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    gan_input = layers.Input(shape=(100,))\n",
        "    generated_image = generator(gan_input)\n",
        "    gan_output = discriminator(generated_image)\n",
        "\n",
        "    gan = models.Model(gan_input, gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "\n",
        "    return gan\n",
        "\n",
        "# Навчання GAN\n",
        "def train_gan(generator, discriminator, gan, data, epochs=10000, batch_size=64):\n",
        "    for epoch in range(epochs):\n",
        "        # Вибірка реальних зображень\n",
        "        idx = np.random.randint(0, data.shape[0], batch_size)\n",
        "        real_images = data[idx]\n",
        "\n",
        "        # Генерація випадкових шумів та фейкових зображень\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        fake_images = generator.predict(noise)\n",
        "\n",
        "        # Створення міток для реальних та фейкових зображень\n",
        "        real_labels = np.ones((batch_size, 1))\n",
        "        fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "        # Навчання дискримінатора\n",
        "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Генерація шуму для навчання генератора через GAN\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "        # Навчання генератора через GAN\n",
        "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Вивід прогресу навчання\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}%] [G loss: {g_loss}]\")\n",
        "\n",
        "# Завантаження датасету\n",
        "data = load_cifar10()\n",
        "\n",
        "# Створення генератора та дискримінатора\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Побудова та компіляція GAN\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Навчання GAN\n",
        "train_gan(generator, discriminator, gan, data, epochs=10000, batch_size=64)\n",
        "\n",
        "# Функція для передобробки зразка зображення\n",
        "def preprocess_image(image_path, target_size=(32, 32)):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize(target_size)\n",
        "    image_array = np.array(image) / 127.5 - 1  # нормалізація до [-1, 1]\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # додавання batch dimension\n",
        "    return image_array\n",
        "\n",
        "# Функція для генерації зображення\n",
        "def generate_image(generator, sample_image):\n",
        "    # Підготовка латентного простору (шуму)\n",
        "    noise = np.random.normal(0, 1, (1, 100))  # можна покращити шляхом використання особливостей sample_image\n",
        "\n",
        "    # Генерація зображення\n",
        "    generated_image = generator.predict(noise)\n",
        "    generated_image = (generated_image * 127.5 + 127.5).astype(np.uint8)  # зворотна нормалізація до [0, 255]\n",
        "    return generated_image\n",
        "\n",
        "# Завантаження та передобробка зображення\n",
        "sample_image_path = 'cat2.jpg'  # замініть на шлях до вашого зразка\n",
        "sample_image = preprocess_image(sample_image_path)\n",
        "\n",
        "# Генерація зображення\n",
        "generated_image = generate_image(generator, sample_image)\n",
        "\n",
        "# Візуалізація згенерованого зображення\n",
        "plt.imshow(generated_image[0])\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ]
}